<!DOCTYPE html> 
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Multilingual Emotion Recognition from Speech</title>
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600&family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">
  <style>
    /* ==== Futuristic dark theme ==== */
    :root {
      --primary: #E0E6ED;
      --secondary: #9AA5B1;
      --accent: #00E5FF;
      --background: #0A0F1C;
      --card-bg: #141B2D;
      --glow: 0 0 10px rgba(0, 229, 255, 0.6), 0 0 20px rgba(0, 229, 255, 0.3);
    }
    body {
      font-family: 'Roboto', sans-serif;
      background: radial-gradient(circle at top left, #0D1526, #0A0F1C 70%);
      padding: 20px;
      color: var(--primary);
      margin: 0;
    }
    .container {
      max-width: 900px;
      margin: auto;
      background: var(--card-bg);
      border-radius: 16px;
      box-shadow: 0 0 25px rgba(0,0,0,0.6);
      overflow: hidden;
    }
    .header {
      background: linear-gradient(90deg, #0F2027, #203A43, #2C5364);
      color: var(--primary);
      padding: 40px 20px;
      text-align: center;
    }
    .header h1 {
      font-family: 'Orbitron', sans-serif;
      font-weight: 600;
      margin: 0;
      font-size: 2em;
      text-shadow: var(--glow);
      letter-spacing: 1px;
    }
    .subheader {
      font-size: 0.9em;
      color: var(--secondary);
      margin-top: 10px;
    }
    .content {
      padding: 30px;
      line-height: 1.6;
    }
    .description {
      margin-bottom: 25px;
      padding: 20px;
      background: rgba(20, 30, 50, 0.8);
      border-left: 4px solid var(--accent);
      border-radius: 10px;
      font-size: 0.95em;
    }
    .upload-container {
      border: 2px dashed rgba(0, 229, 255, 0.5);
      padding: 30px;
      border-radius: 12px;
      text-align: center;
      background: rgba(10, 15, 28, 0.6);
      margin-bottom: 30px;
      transition: all 0.3s;
    }
    .upload-container:hover {
      background: rgba(20, 30, 50, 0.9);
      box-shadow: var(--glow);
    }
    button {
      background: var(--accent);
      color: #0A0F1C;
      border: none;
      padding: 12px 24px;
      margin-top: 15px;
      border-radius: 8px;
      cursor: pointer;
      font-size: 0.95em;
      font-weight: 500;
      letter-spacing: 0.5px;
      transition: transform 0.2s, box-shadow 0.3s;
    }
    button:hover {
      transform: translateY(-2px);
      box-shadow: var(--glow);
    }
    input[type="file"] {
      margin-top: 12px;
      color: var(--secondary);
    }
    #result {
      margin-top: 30px;
    }
    .result-card {
      padding: 22px;
      border-left: 4px solid var(--accent);
      border-radius: 12px;
      background: rgba(20, 30, 50, 0.85);
      box-shadow: 0 0 15px rgba(0,229,255,0.2);
    }
    .result-card strong {
      color: var(--accent);
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 14px;
      font-size: 0.9em;
    }
    th, td {
      border: 1px solid rgba(255,255,255,0.1);
      padding: 10px;
      text-align: center;
      color: var(--secondary);
    }
    th {
      background: rgba(0,229,255,0.1);
      font-weight: 600;
      color: var(--primary);
    }
    .processing {
      text-align: center;
      padding: 25px;
    }
    .spinner {
      width: 55px;
      height: 55px;
      border: 4px solid rgba(255,255,255,0.1);
      border-top: 4px solid var(--accent);
      border-radius: 50%;
      animation: spin 1s linear infinite;
      margin: auto;
      box-shadow: var(--glow);
    }
    @keyframes spin {
      0% {transform: rotate(0deg);}
      100% {transform: rotate(360deg);}
    }
    .disclaimer {
      margin-top: 30px;
      padding: 18px;
      font-size: 0.85em;
      color: var(--secondary);
      border-top: 1px solid rgba(255,255,255,0.1);
      line-height: 1.4;
    }
    .disclaimer strong {
      color: var(--accent);
    }
    @media (max-width: 700px) {
      .content {
        padding: 20px;
      }
      .header h1 {
        font-size: 1.5em;
      }
      button {
        width: 100%;
        margin-top: 10px;
      }
      .upload-container {
        padding: 20px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>Multilingual Emotion Recognition from Speech</h1>
      <div class="subheader">Final Master’s Project in Artificial Intelligence</div>
    </div>
    <div class="content">

      <!-- Project description --> 
      <div class="description"> 
        <p> This project introduces an AI model for <strong>emotion recognition in speech</strong>, designed to work across <strong>languages and demographics</strong>. By leveraging <em>Whisper’s encoder</em> for embedding generation, the system aims to provide a robust and fair solution for multicultural emotion detection. The goal is to ensure accessibility and inclusivity, regardless of the speaker’s background. </p> <p> Learn more about the implementation on <a href="https://github.com/faler08/Multi-cultural-SER-Web-App" target="_blank" style="color:var(--accent);">GitHub</a>. 
        </p> 
      </div>

      <!-- Upload file -->
      <div class="upload-container">
        <p><strong>Upload an audio file (.wav)</strong></p>
        <form id="upload-form">
          <input type="file" name="file" accept=".wav" required>
          <br>
          <button type="submit">Analyze Emotion</button>
        </form>
      </div>

      <!-- Record audio -->
      <div class="upload-container">
        <p><strong>Or record your voice in real-time</strong></p>
        <button id="start-record">Start Recording</button>
        <button id="stop-record" disabled>Stop & Analyze</button>
        <p id="recording-status" style="margin-top:12px;color:var(--secondary)"></p>
      </div>

      <div id="result"></div>

      <!-- Disclaimer --> 
       <div class="disclaimer"> 
        <p> 
          <strong>Disclaimer:</strong> This application is a research prototype developed as part of a Master’s thesis. It is not intended for clinical use, nor should it be used as a substitute for professional judgment. The detection of emotions in speech is a complex task, and this model provides only probabilistic outputs. In line with the <em>EU AI Act</em>, the system is presented transparently as an experimental tool. It does not attempt to reduce human emotional experience to a single label, nor should it be relied upon for sensitive decision-making regarding an individual’s well-being.
        </p> 
      </div>
    </div>
  </div>

  <script>
    const resultDiv = document.getElementById("result");

    // ========== File upload ==========
    const uploadForm = document.getElementById("upload-form");
    uploadForm.addEventListener("submit", async (e) => {
      e.preventDefault();
      const formData = new FormData(uploadForm);
      await sendToServer(formData);
    });

    // ========== Recording ==========
    let mediaRecorder;
    let audioChunks = [];
    const startBtn = document.getElementById("start-record");
    const stopBtn = document.getElementById("stop-record");
    const statusText = document.getElementById("recording-status");

    startBtn.addEventListener("click", async () => {
      audioChunks = [];
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.start();
      statusText.textContent = "Recording...";
      startBtn.disabled = true;
      stopBtn.disabled = false;

      mediaRecorder.ondataavailable = event => {
        audioChunks.push(event.data);
      };
    });

    stopBtn.addEventListener("click", async () => {
      mediaRecorder.stop();
      statusText.textContent = "Processing recording...";
      stopBtn.disabled = true;
      startBtn.disabled = false;

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const arrayBuffer = await audioBlob.arrayBuffer();
        const audioContext = new AudioContext();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        const wavBlob = encodeWAV(audioBuffer.getChannelData(0), audioBuffer.sampleRate);

        const formData = new FormData();
        formData.append("file", wavBlob, "recording.wav");
        await sendToServer(formData);
        statusText.textContent = "";
      };
    });

    // ========== WAV encoder ==========
    function encodeWAV(samples, sampleRate) {
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);

      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, samples.length * 2, true);

      let offset = 44;
      for (let i = 0; i < samples.length; i++, offset += 2) {
        const s = Math.max(-1, Math.min(1, samples[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      }
      return new Blob([view], { type: "audio/wav" });
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    // ========== Common function ==========
    async function sendToServer(formData) {
      resultDiv.innerHTML = `
        <div class="processing">
          <div class="spinner"></div>
          <p>Analyzing audio...</p>
        </div>
      `;

      try {
        const response = await fetch("/predict", {
          method: "POST",
          body: formData
        });
        const data = await response.json();

        if (data.error) {
          resultDiv.innerHTML = `<div class="result-card"><p style="color:red">${data.error}</p></div>`;
          return;
        }

        let html = `<div class="result-card">`;
        html += `<div class="prediction"><strong>Detected Emotion:</strong> ${data.prediction}</div>`;
        html += `<table><tr><th>Emotion</th><th>Probability</th></tr>`;
        for (const [label, prob] of Object.entries(data.probabilities)) {
          html += `<tr><td>${label}</td><td>${(prob*100).toFixed(2)}%</td></tr>`;
        }
        html += "</table></div>";

        resultDiv.innerHTML = html;
      } catch (err) {
        resultDiv.innerHTML = `<div class="result-card"><p style="color:red">Network error</p></div>`;
      }
    }
  </script>
</body>
</html>